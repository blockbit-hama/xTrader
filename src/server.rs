use std::sync::Arc;
use std::sync::mpsc;
use std::collections::HashMap;
use tokio::sync::Mutex;
use tokio::sync::broadcast;
use axum::Router;
use tower_http::cors::CorsLayer;
use tower_http::trace::TraceLayer;
use sqlx::sqlite::SqlitePool;
use log::{info, warn, debug, error};

use crate::api::create_api_router;
use crate::matching_engine::engine::MatchingEngine;
use crate::matching_engine::model::{Order, ExecutionReport};
use crate::mdp::MarketDataPublisher;
use crate::sequencer::OrderSequencer;
use crate::api::models::WebSocketMessage;
use crate::db::AsyncCommitManager;
use crate::mq::{RedisStreamsProducer, RedisConsumerManager, ConsumerConfig, KafkaProducer, KafkaConsumerConfig, MDPConsumer, ExternalExchangeConsumer, RegulatoryConsumer, AnalyticsConsumer, RabbitMQProducer, RabbitMQConsumerConfig, WebSocketServerConsumer, LoadBalancerConsumer, DeadLetterQueueConsumer, LocalBackupQueue, MQHealthMonitor, RecoveryManager, HealthCheckConfig, RecoveryConfig};
use crate::mdp::{MDPConsumer as MDPConsumerType, MDPConsumerConfig, MDPApiServerBuilder, MDPCacheManager, CacheConfig};
use crate::external::{ExternalPriceSyncManager, PriceSyncConfig, RegulatoryReportingManager, RegulatoryReportingConfig, AnalyticsIntegrationManager, AnalyticsIntegrationConfig};
use crate::performance::{BatchProcessor, BatchProcessorConfig, WorkerPool, ParallelConsumerConfig, CacheOptimizer, CacheOptimizerConfig, MetricsCollector, MetricsCollectorConfig, PerformanceAnalyzer};
use crate::monitoring::{SystemHealthMonitor, HealthCheckConfig as MonitoringHealthCheckConfig, NotificationSystem, NotificationConfig, DashboardServer, DashboardConfig, DashboardDataProvider, LogAnalyzer, LogAnalyzerConfig};

/// ì‚¬ìš©ì ì”ê³  ì •ë³´
#[derive(Debug, Clone)]
pub struct UserBalance {
    pub krw: u64,
    pub btc: u64,
}

impl Default for UserBalance {
    fn default() -> Self {
        Self {
            krw: 50_000_000_000, // 500ì–µì› (í…ŒìŠ¤íŠ¸ìš©)
            btc: 100_000_000,    // 100 BTC (í…ŒìŠ¤íŠ¸ìš©)
        }
    }
}

/// ì„œë²„ ì„¤ì •
#[derive(Clone)]
pub struct ServerConfig {
    pub rest_port: u16,
    pub ws_port: u16,
    pub symbols: Vec<String>,
}

impl Default for ServerConfig {
    fn default() -> Self {
        Self {
            rest_port: 7000,
            ws_port: 7001,
            symbols: vec!["BTC-KRW".into(), "ETH-KRW".into(), "AAPL".into()],
        }
    }
}

/// ì„œë²„ ìƒíƒœ
#[derive(Clone)]
pub struct ServerState {
    pub engine: Arc<Mutex<MatchingEngine>>,
    pub execution_tx: broadcast::Sender<WebSocketMessage>,
    pub order_tx: mpsc::Sender<Order>,
    pub mdp: Arc<Mutex<MarketDataPublisher>>,
    pub db_pool: SqlitePool,
}

/// ì„œë²„ ì‹œì‘
pub async fn start_server(config: ServerConfig, db_pool: SqlitePool) -> Result<(), Box<dyn std::error::Error>> {
    println!("xTrader ì„œë²„ ì‹œì‘ ì¤‘...");

    // ì±„ë„ ìƒì„±
    let (order_tx, order_rx) = mpsc::channel::<Order>();
    let (exec_tx, exec_rx) = mpsc::channel::<ExecutionReport>();
    
    // ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì±„ë„ ìƒì„± (WebSocketìš©)
    let (broadcast_tx, _broadcast_rx) = broadcast::channel(1000);

    // ğŸš€ ì´ˆê³ ì„±ëŠ¥: ë¹„ë™ê¸° ì»¤ë°‹ ë§¤ë‹ˆì € ìƒì„±
    let async_commit_mgr = Arc::new(
        AsyncCommitManager::new(db_pool.clone())
            .with_config(100, 10) // ë°°ì¹˜ í¬ê¸°: 100, ê°„ê²©: 10ms
    );

    // ğŸš€ Redis Streams Producer ì´ˆê¸°í™”
    let redis_producer = match RedisStreamsProducer::new("redis://localhost:6379", "executions").await {
        Ok(producer) => {
            println!("âœ… Redis Streams Producer ì´ˆê¸°í™” ì™„ë£Œ");
            Some(Arc::new(producer))
        }
        Err(e) => {
            println!("âš ï¸ Redis Streams ì—°ê²° ì‹¤íŒ¨: {} (ê³„ì† ì‹¤í–‰)", e);
            None
        }
    };

    // ğŸš€ Kafka Producer ì´ˆê¸°í™”
    let kafka_producer = match KafkaProducer::new(&["localhost:9092".to_string()], "market-data").await {
        Ok(producer) => {
            println!("âœ… Kafka Producer ì´ˆê¸°í™” ì™„ë£Œ");
            Some(Arc::new(producer))
        }
        Err(e) => {
            println!("âš ï¸ Kafka ì—°ê²° ì‹¤íŒ¨: {} (ê³„ì† ì‹¤í–‰)", e);
            None
        }
    };

    // ğŸš€ RabbitMQ Producer ì´ˆê¸°í™”
    let rabbitmq_producer = match RabbitMQProducer::new("amqp://localhost:5672", "websocket_notifications").await {
        Ok(producer) => {
            println!("âœ… RabbitMQ Producer ì´ˆê¸°í™” ì™„ë£Œ");
            
            // Exchange ë° Dead Letter Queue ì„¤ì •
            if let Err(e) = producer.setup_exchange().await {
                println!("âš ï¸ RabbitMQ Exchange ì„¤ì • ì‹¤íŒ¨: {}", e);
            }
            if let Err(e) = producer.setup_dead_letter_queue().await {
                println!("âš ï¸ RabbitMQ Dead Letter Queue ì„¤ì • ì‹¤íŒ¨: {}", e);
            }
            
            Some(Arc::new(producer))
        }
        Err(e) => {
            println!("âš ï¸ RabbitMQ ì—°ê²° ì‹¤íŒ¨: {} (ê³„ì† ì‹¤í–‰)", e);
            None
        }
    };

    // ğŸš€ ì¥ì•  ë³µêµ¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    let backup_queue = Arc::new(LocalBackupQueue::new(
        "/tmp/mq_backup".to_string(),
        1000,  // ìµœëŒ€ ë©”ëª¨ë¦¬ í í¬ê¸°
        5000,  // 5ì´ˆë§ˆë‹¤ ë””ìŠ¤í¬ ë°±ì—…
    ));

    let health_monitor = Arc::new(MQHealthMonitor::new(
        HealthCheckConfig::default(),
        backup_queue.clone(),
    ));

    let recovery_manager = Arc::new(RecoveryManager::new(
        backup_queue.clone(),
        health_monitor.clone(),
        RecoveryConfig::default(),
    ));

    // í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    health_monitor.start_monitoring().await;
    println!("âœ… MQ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘");

    // ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    recovery_manager.start_recovery().await;
    println!("âœ… MQ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ ì‹œì‘");

    // ì£¼ê¸°ì  ë¦¬í¬íŠ¸ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œ)
    let health_monitor_clone = health_monitor.clone();
    let recovery_manager_clone = recovery_manager.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(30));
        
        loop {
            interval.tick().await;
            
            // í—¬ìŠ¤ ë¦¬í¬íŠ¸ ì¶œë ¥
            let health_report = health_monitor_clone.generate_health_report().await;
            println!("{}", health_report);
            
            // ë³µêµ¬ ë¦¬í¬íŠ¸ ì¶œë ¥
            let recovery_report = recovery_manager_clone.generate_recovery_report().await;
            println!("{}", recovery_report);
        }
    });

    // ğŸš€ MDP Consumer ë° API ì„œë²„ ì´ˆê¸°í™”
    let mdp_config = MDPConsumerConfig::default();
    let mdp_consumer = Arc::new(MDPConsumerType::new(mdp_config));
    
    // MDP Consumer ì‹¤í–‰
    let mdp_consumer_clone = mdp_consumer.clone();
    tokio::spawn(async move {
        if let Err(e) = mdp_consumer_clone.run().await {
            error!("MDP Consumer ì‹¤í–‰ ì‹¤íŒ¨: {}", e);
        }
    });
    println!("âœ… MDP Consumer ì‹œì‘");

    // ìºì‹œ ê´€ë¦¬ì ì´ˆê¸°í™”
    let cache_config = CacheConfig::default();
    let cache_manager = Arc::new(MDPCacheManager::new(cache_config));
    cache_manager.start().await;
    println!("âœ… MDP ìºì‹œ ê´€ë¦¬ì ì‹œì‘");

    // MDP API ì„œë²„ ì‹œì‘
    let mdp_consumer_for_api = mdp_consumer.clone();
    tokio::spawn(async move {
        let builder = MDPApiServerBuilder::new()
            .consumer(mdp_consumer_for_api)
            .port(3001)
            .host("0.0.0.0".to_string());
        
        if let Err(e) = builder.run().await {
            error!("MDP API ì„œë²„ ì‹¤í–‰ ì‹¤íŒ¨: {}", e);
        }
    });
    println!("âœ… MDP API ì„œë²„ ì‹œì‘ (í¬íŠ¸: 3001)");

    // ğŸš€ ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™ ì´ˆê¸°í™”
    let price_sync_config = PriceSyncConfig::default();
    let price_sync_manager = Arc::new(ExternalPriceSyncManager::new(price_sync_config));
    
    // ê°€ê²© ë™ê¸°í™” ì‹œì‘
    let price_sync_manager_clone = price_sync_manager.clone();
    tokio::spawn(async move {
        price_sync_manager_clone.start_sync().await;
    });
    println!("âœ… ì™¸ë¶€ ê±°ë˜ì†Œ ê°€ê²© ë™ê¸°í™” ì‹œì‘");

    // ê·œì œ ë³´ê³  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    let regulatory_config = RegulatoryReportingConfig::default();
    let regulatory_manager = Arc::new(RegulatoryReportingManager::new(regulatory_config));
    
    // ê·œì œ ë³´ê³  ì‹œì‘
    let regulatory_manager_clone = regulatory_manager.clone();
    tokio::spawn(async move {
        regulatory_manager_clone.start_reporting().await;
    });
    println!("âœ… ê·œì œ ê¸°ê´€ ë³´ê³  ì‹œìŠ¤í…œ ì‹œì‘");

    // ë¶„ì„ ì‹œìŠ¤í…œ ì—°ë™ ì´ˆê¸°í™”
    let analytics_config = AnalyticsIntegrationConfig::default();
    let analytics_manager = Arc::new(AnalyticsIntegrationManager::new(analytics_config));
    
    // ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘
    let analytics_manager_clone = analytics_manager.clone();
    tokio::spawn(async move {
        analytics_manager_clone.start_analysis().await;
    });
    println!("âœ… ë¶„ì„ ì‹œìŠ¤í…œ ì—°ë™ ì‹œì‘");

    // ì£¼ê¸°ì  ì™¸ë¶€ ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬í¬íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ)
    let price_sync_manager_report = price_sync_manager.clone();
    let regulatory_manager_report = regulatory_manager.clone();
    let analytics_manager_report = analytics_manager.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(60));
        
        loop {
            interval.tick().await;
            
            // ê°€ê²© ë™ê¸°í™” í†µê³„
            let price_stats = price_sync_manager_report.get_sync_stats().await;
            println!("ğŸ“Š ê°€ê²© ë™ê¸°í™” í†µê³„: ì‹¬ë³¼ {}ê°œ, ê±°ë˜ì†Œ {}ê°œ, ì°¨ìµê±°ë˜ ê¸°íšŒ {}ê°œ", 
                     price_stats.symbols_synced, price_stats.exchanges_monitored, price_stats.total_arbitrage_opportunities);
            
            // ê·œì œ ë³´ê³  í†µê³„
            let regulatory_stats = regulatory_manager_report.get_reporting_stats().await;
            println!("ğŸ“‹ ê·œì œ ë³´ê³  í†µê³„: ê±°ë˜ {}ê±´, ì˜ì‹¬í™œë™ {}ê±´, ë³´ê³ ì„œ {}ê±´", 
                     regulatory_stats.total_transactions, regulatory_stats.total_suspicious_activities, regulatory_stats.total_reports);
            
            // ë¶„ì„ ì‹œìŠ¤í…œ í†µê³„
            let analytics_stats = analytics_manager_report.get_analysis_stats().await;
            println!("ğŸ”¬ ë¶„ì„ ì‹œìŠ¤í…œ í†µê³„: ëŒ€ê¸° {}ê±´, í™œì„± {}ê±´, ì™„ë£Œ {}ê±´, í‰ê·  ì‹ ë¢°ë„ {:.2}", 
                     analytics_stats.pending_requests, analytics_stats.active_requests, analytics_stats.total_completed, analytics_stats.average_confidence);
        }
    });

    // ğŸš€ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    let batch_config = BatchProcessorConfig::default();
    let batch_processor = Arc::new(BatchProcessor::new(batch_config, |data| {
        // Mock ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
        data.into_iter().map(|x| Ok(format!("processed_{}", x))).collect()
    }));
    
    // ë°°ì¹˜ ì²˜ë¦¬ê¸° ì‹œì‘
    let batch_processor_clone = batch_processor.clone();
    tokio::spawn(async move {
        batch_processor_clone.start().await;
    });
    println!("âœ… ë°°ì¹˜ ì²˜ë¦¬ê¸° ì‹œì‘");

    // ë³‘ë ¬ ì†Œë¹„ ì›Œì»¤ í’€ ì´ˆê¸°í™”
    let parallel_config = ParallelConsumerConfig::default();
    let worker_pool = Arc::new(WorkerPool::new(parallel_config, |data| {
        // Mock ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜
        Ok(format!("processed_{}", data))
    }));
    
    // ì›Œì»¤ í’€ ì‹œì‘
    let worker_pool_clone = worker_pool.clone();
    tokio::spawn(async move {
        worker_pool_clone.start().await;
    });
    println!("âœ… ë³‘ë ¬ ì†Œë¹„ ì›Œì»¤ í’€ ì‹œì‘");

    // ìºì‹œ ìµœì í™”ê¸° ì´ˆê¸°í™”
    let cache_config = CacheOptimizerConfig::default();
    let cache_optimizer = Arc::new(CacheOptimizer::new(cache_config));
    
    // ìºì‹œ ìµœì í™”ê¸° ì‹œì‘
    let cache_optimizer_clone = cache_optimizer.clone();
    tokio::spawn(async move {
        cache_optimizer_clone.start().await;
    });
    println!("âœ… ìºì‹œ ìµœì í™”ê¸° ì‹œì‘");

    // ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    let metrics_config = MetricsCollectorConfig::default();
    let metrics_collector = Arc::new(MetricsCollector::new(metrics_config));
    
    // ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì‹œì‘
    let metrics_collector_clone = metrics_collector.clone();
    tokio::spawn(async move {
        metrics_collector_clone.start().await;
    });
    println!("âœ… ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì‹œì‘");

    // ì„±ëŠ¥ ë¶„ì„ê¸° ì´ˆê¸°í™”
    let performance_analyzer = Arc::new(PerformanceAnalyzer::new(metrics_collector.clone()));

    // ì£¼ê¸°ì  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (ë°±ê·¸ë¼ìš´ë“œ)
    let batch_processor_monitor = batch_processor.clone();
    let worker_pool_monitor = worker_pool.clone();
    let cache_optimizer_monitor = cache_optimizer.clone();
    let metrics_collector_monitor = metrics_collector.clone();
    let performance_analyzer_monitor = performance_analyzer.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(30));
        
        loop {
            interval.tick().await;
            
            // ë°°ì¹˜ ì²˜ë¦¬ í†µê³„
            let batch_stats = batch_processor_monitor.get_stats().await;
            println!("ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ í†µê³„: ì´ ë°°ì¹˜ {}ê°œ, ë©”ì‹œì§€ {}ê°œ, ì²˜ë¦¬ëŸ‰ {:.1}/ì´ˆ", 
                     batch_stats.total_batches, batch_stats.total_messages, batch_stats.throughput_per_second);
            
            // ë³‘ë ¬ ì†Œë¹„ í†µê³„
            let parallel_stats = worker_pool_monitor.get_stats().await;
            println!("âš¡ ë³‘ë ¬ ì†Œë¹„ í†µê³„: ì›Œì»¤ {}ê°œ, ì²˜ë¦¬ {}ê°œ, ì‹¤íŒ¨ {}ê°œ", 
                     parallel_stats.total_workers, parallel_stats.total_processed, parallel_stats.total_failed);
            
            // ìºì‹œ í†µê³„
            let cache_stats = cache_optimizer_monitor.get_stats().await;
            println!("ğŸ’¾ ìºì‹œ í†µê³„: íˆíŠ¸ìœ¨ {:.1}%, L1 {}ê°œ, L2 {}ê°œ, L3 {}ê°œ", 
                     cache_stats.hit_rate * 100.0, cache_stats.l1_size, cache_stats.l2_size, cache_stats.l3_size);
            
            // ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸
            let performance_report = performance_analyzer_monitor.generate_performance_report().await;
            println!("ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„: CPU {:.1}%, ë©”ëª¨ë¦¬ {:.1}%, ì‘ë‹µì‹œê°„ {:.1}ms, ì—ëŸ¬ìœ¨ {:.2}%", 
                     performance_report.average_cpu_usage, performance_report.average_memory_usage, 
                     performance_report.average_response_time, performance_report.error_rate);
            
            // ì¶”ì²œì‚¬í•­ ì¶œë ¥
            for recommendation in &performance_report.recommendations {
                println!("ğŸ’¡ ì¶”ì²œ: {}", recommendation);
            }
        }
    });

    // ğŸ” ëª¨ë‹ˆí„°ë§ ë° í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    let notification_config = NotificationConfig::default();
    let notification_system = Arc::new(NotificationSystem::new(notification_config));
    
    // ì•Œë¦¼ ì‹œìŠ¤í…œ ì‹œì‘
    let notification_system_clone = notification_system.clone();
    tokio::spawn(async move {
        notification_system_clone.start().await;
    });
    println!("âœ… ì•Œë¦¼ ì‹œìŠ¤í…œ ì‹œì‘");

    // í—¬ìŠ¤ì²´í¬ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    let health_config = MonitoringHealthCheckConfig::default();
    let health_monitor = Arc::new(SystemHealthMonitor::new(health_config, move |message, _type| {
        println!("ğŸš¨ í—¬ìŠ¤ì²´í¬ ì•Œë¦¼: {}", message);
        Ok(())
    }));
    
    // í—¬ìŠ¤ì²´í¬ ëª¨ë‹ˆí„° ì‹œì‘
    let health_monitor_clone = health_monitor.clone();
    tokio::spawn(async move {
        health_monitor_clone.start().await;
    });
    println!("âœ… í—¬ìŠ¤ì²´í¬ ëª¨ë‹ˆí„° ì‹œì‘");

    // ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì œê³µì ì´ˆê¸°í™”
    let dashboard_data_provider = Arc::new(DashboardDataProvider::new());
    
    // ëŒ€ì‹œë³´ë“œ ì„œë²„ ì´ˆê¸°í™”
    let dashboard_config = DashboardConfig::default();
    let dashboard_server = Arc::new(DashboardServer::new(dashboard_config));
    
    // ëŒ€ì‹œë³´ë“œ ì„œë²„ ì‹œì‘
    let dashboard_server_clone = dashboard_server.clone();
    let dashboard_data_provider_clone = dashboard_data_provider.clone();
    tokio::spawn(async move {
        dashboard_server_clone.start(dashboard_data_provider_clone).await;
    });
    println!("âœ… ëŒ€ì‹œë³´ë“œ ì„œë²„ ì‹œì‘");

    // ë¡œê·¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
    let log_analyzer_config = LogAnalyzerConfig::default();
    let log_analyzer = Arc::new(LogAnalyzer::new(log_analyzer_config));
    
    // ë¡œê·¸ ë¶„ì„ê¸° ì‹œì‘
    let log_analyzer_clone = log_analyzer.clone();
    tokio::spawn(async move {
        log_analyzer_clone.start().await;
    });
    println!("âœ… ë¡œê·¸ ë¶„ì„ê¸° ì‹œì‘");

    // ì£¼ê¸°ì  ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ)
    let health_monitor_report = health_monitor.clone();
    let notification_system_report = notification_system.clone();
    let dashboard_server_report = dashboard_server.clone();
    let log_analyzer_report = log_analyzer.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(60));
        
        loop {
            interval.tick().await;
            
            // ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ ë¦¬í¬íŠ¸
            let system_health = health_monitor_report.get_system_health().await;
            println!("ğŸ¥ ì‹œìŠ¤í…œ í—¬ìŠ¤: ì „ì²´ ìƒíƒœ {}, ì •ìƒ {}ê°œ, ê²½ê³  {}ê°œ, ìœ„í—˜ {}ê°œ", 
                     match system_health.overall_status {
                         crate::monitoring::HealthStatus::Healthy => "ì •ìƒ",
                         crate::monitoring::HealthStatus::Warning => "ê²½ê³ ",
                         crate::monitoring::HealthStatus::Critical => "ìœ„í—˜",
                         crate::monitoring::HealthStatus::Unknown => "ì•Œìˆ˜ì—†ìŒ",
                     },
                     system_health.healthy_services, 
                     system_health.warning_services, 
                     system_health.critical_services);
            
            // ì¶”ì²œì‚¬í•­ ì¶œë ¥
            for recommendation in &system_health.recommendations {
                println!("ğŸ’¡ ì¶”ì²œ: {}", recommendation);
            }
            
            // ì•Œë¦¼ ì‹œìŠ¤í…œ í†µê³„
            let notification_stats = notification_system_report.get_stats().await;
            println!("ğŸ“¢ ì•Œë¦¼ í†µê³„: ë°œì†¡ {}ê°œ, ì‹¤íŒ¨ {}ê°œ, ì„±ê³µë¥  {:.1}%", 
                     notification_stats.total_sent, 
                     notification_stats.total_failed, 
                     notification_stats.success_rate * 100.0);
            
            // ëŒ€ì‹œë³´ë“œ í†µê³„
            let dashboard_stats = dashboard_server_report.get_dashboard_stats().await;
            println!("ğŸ“Š ëŒ€ì‹œë³´ë“œ: ë ˆì´ì•„ì›ƒ {}ê°œ, ìœ„ì ¯ {}ê°œ, ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ {}ê°œ", 
                     dashboard_stats.total_layouts, 
                     dashboard_stats.total_widgets, 
                     dashboard_stats.connected_clients);
            
            // ë¡œê·¸ ë¶„ì„ í†µê³„
            let log_stats = log_analyzer_report.get_stats().await;
            println!("ğŸ“ ë¡œê·¸ ë¶„ì„: ì´ {}ê°œ, ì—ëŸ¬ìœ¨ {:.2}%, ê²½ê³ ìœ¨ {:.2}%, ëª¨ë“ˆ {}ê°œ", 
                     log_stats.total_entries, 
                     log_stats.error_rate, 
                     log_stats.warning_rate, 
                     log_stats.unique_modules);
        }
    });

    // ë§¤ì¹­ ì—”ì§„ ìƒì„± (RabbitMQ Producer ì´ˆê¸°í™” í›„)
    let mut engine = MatchingEngine::new(config.symbols.clone(), exec_tx, rabbitmq_producer.clone());
    engine.set_broadcast_channel(broadcast_tx.clone());
    let engine = Arc::new(Mutex::new(engine));

    // MDP ìƒì„±
    let mut mdp = MarketDataPublisher::new(1000);
    mdp.set_broadcast_channel(broadcast_tx.clone());
    let mdp = Arc::new(Mutex::new(mdp));

    // ë¹„ë™ê¸° ì»¤ë°‹ ë£¨í”„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
    let commit_mgr_clone = async_commit_mgr.clone();
    tokio::spawn(async move {
        commit_mgr_clone.run_batch_commit_loop().await;
    });

    // ì‹œí€€ì„œìš© ì±„ë„ ìƒì„±
    let (sequencer_tx, sequencer_rx) = mpsc::channel::<Order>();

    // ì‹œí€€ì„œ ìƒì„± ë° ì‹¤í–‰
    let mut sequencer = OrderSequencer::new(
        order_rx,
        sequencer_tx,
        exec_rx,
        broadcast_tx.clone(),
        mdp.clone(),
        async_commit_mgr.clone(),
        redis_producer.clone(),
        kafka_producer.clone(),
        rabbitmq_producer.clone(),
    );

    // ì‹œí€€ì„œ ì‹¤í–‰ íƒœìŠ¤í¬
    tokio::spawn(async move {
        sequencer.run().await;
    });

    // ğŸš€ Redis Consumer Manager ì´ˆê¸°í™” ë° ì‹¤í–‰
    let redis_producer_clone = redis_producer.clone();
    if redis_producer_clone.is_some() {
        let consumer_configs = vec![
            ConsumerConfig {
                redis_url: "redis://localhost:6379".to_string(),
                stream_name: "executions".to_string(),
                consumer_group: "execution_processors".to_string(),
                worker_id: "worker-1".to_string(),
                batch_size: 100,
                processing_interval_ms: 100,
            },
            ConsumerConfig {
                redis_url: "redis://localhost:6379".to_string(),
                stream_name: "executions".to_string(),
                consumer_group: "execution_processors".to_string(),
                worker_id: "worker-2".to_string(),
                batch_size: 100,
                processing_interval_ms: 100,
            },
            ConsumerConfig {
                redis_url: "redis://localhost:6379".to_string(),
                stream_name: "executions".to_string(),
                consumer_group: "execution_processors".to_string(),
                worker_id: "worker-3".to_string(),
                batch_size: 100,
                processing_interval_ms: 100,
            },
        ];

        match RedisConsumerManager::new(consumer_configs, db_pool.clone()).await {
            Ok(consumer_manager) => {
                println!("âœ… Redis Consumer Manager ì´ˆê¸°í™” ì™„ë£Œ (3ê°œ Worker)");
                
                // Consumer Manager ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
                tokio::spawn(async move {
                    if let Err(e) = consumer_manager.start_all_workers().await {
                        println!("âŒ Redis Consumer Manager ì‹¤í–‰ ì˜¤ë¥˜: {}", e);
                    }
                });
            }
            Err(e) => {
                println!("âš ï¸ Redis Consumer Manager ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e);
            }
        }
    }

    // ğŸš€ Kafka Consumer Manager ì´ˆê¸°í™” ë° ì‹¤í–‰
    if let Some(_kafka_producer) = &kafka_producer {
        // MDP Consumer (Market Data Publisher)
        let mdp_config = KafkaConsumerConfig {
            kafka_brokers: vec!["localhost:9092".to_string()],
            topic_name: "market-data".to_string(),
            consumer_group: "mdp-group".to_string(),
            worker_id: "mdp-worker".to_string(),
            batch_size: 100,
            processing_interval_ms: 100,
        };

        match MDPConsumer::new(mdp_config).await {
            Ok(mdp_consumer) => {
                println!("âœ… MDP Consumer ì´ˆê¸°í™” ì™„ë£Œ");
                
                tokio::spawn(async move {
                    if let Err(e) = mdp_consumer.run().await {
                        println!("âŒ MDP Consumer ì‹¤í–‰ ì˜¤ë¥˜: {}", e);
                    }
                });
            }
            Err(e) => {
                println!("âš ï¸ MDP Consumer ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e);
            }
        }

        // ì™¸ë¶€ ê±°ë˜ì†Œ Consumer
        let external_config = KafkaConsumerConfig {
            kafka_brokers: vec!["localhost:9092".to_string()],
            topic_name: "market-data".to_string(),
            consumer_group: "exchange-sync".to_string(),
            worker_id: "external-worker".to_string(),
            batch_size: 100,
            processing_interval_ms: 100,
        };

        match ExternalExchangeConsumer::new(external_config).await {
            Ok(external_consumer) => {
                println!("âœ… ì™¸ë¶€ ê±°ë˜ì†Œ Consumer ì´ˆê¸°í™” ì™„ë£Œ");
                
                tokio::spawn(async move {
                    if let Err(e) = external_consumer.run().await {
                        println!("âŒ ì™¸ë¶€ ê±°ë˜ì†Œ Consumer ì‹¤í–‰ ì˜¤ë¥˜: {}", e);
                    }
                });
            }
            Err(e) => {
                println!("âš ï¸ ì™¸ë¶€ ê±°ë˜ì†Œ Consumer ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e);
            }
        }

        // ê·œì œ ê¸°ê´€ Consumer
        let regulatory_config = KafkaConsumerConfig {
            kafka_brokers: vec!["localhost:9092".to_string()],
            topic_name: "market-data".to_string(),
            consumer_group: "regulatory".to_string(),
            worker_id: "regulatory-worker".to_string(),
            batch_size: 100,
            processing_interval_ms: 100,
        };

        match RegulatoryConsumer::new(regulatory_config).await {
            Ok(regulatory_consumer) => {
                println!("âœ… ê·œì œ ê¸°ê´€ Consumer ì´ˆê¸°í™” ì™„ë£Œ");
                
                tokio::spawn(async move {
                    if let Err(e) = regulatory_consumer.run().await {
                        println!("âŒ ê·œì œ ê¸°ê´€ Consumer ì‹¤í–‰ ì˜¤ë¥˜: {}", e);
                    }
                });
            }
            Err(e) => {
                println!("âš ï¸ ê·œì œ ê¸°ê´€ Consumer ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e);
            }
        }

        // ë¶„ì„ ì‹œìŠ¤í…œ Consumer
        let analytics_config = KafkaConsumerConfig {
            kafka_brokers: vec!["localhost:9092".to_string()],
            topic_name: "market-data".to_string(),
            consumer_group: "analytics".to_string(),
            worker_id: "analytics-worker".to_string(),
            batch_size: 100,
            processing_interval_ms: 100,
        };

        match AnalyticsConsumer::new(analytics_config).await {
            Ok(analytics_consumer) => {
                println!("âœ… ë¶„ì„ ì‹œìŠ¤í…œ Consumer ì´ˆê¸°í™” ì™„ë£Œ");
                
                tokio::spawn(async move {
                    if let Err(e) = analytics_consumer.run().await {
                        println!("âŒ ë¶„ì„ ì‹œìŠ¤í…œ Consumer ì‹¤í–‰ ì˜¤ë¥˜: {}", e);
                    }
                });
            }
            Err(e) => {
                println!("âš ï¸ ë¶„ì„ ì‹œìŠ¤í…œ Consumer ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e);
            }
        }
    }

    // ğŸš€ RabbitMQ Consumer Manager ì´ˆê¸°í™” ë° ì‹¤í–‰
    if let Some(_rabbitmq_producer) = &rabbitmq_producer {
        // WebSocket ì„œë²„ Consumerë“¤ ì„¤ì •
        let server_configs = vec![
            (
                RabbitMQConsumerConfig {
                    rabbitmq_url: "amqp://localhost:5672".to_string(),
                    exchange_name: "websocket_notifications".to_string(),
                    queue_name: "ws-server-1".to_string(),
                    routing_patterns: vec!["execution.*".to_string(), "orderbook.*".to_string()],
                    worker_id: "ws-worker-1".to_string(),
                    batch_size: 100,
                    processing_interval_ms: 100,
                },
                "ws-server-1".to_string(),
                1000, // ìµœëŒ€ ì—°ê²° ìˆ˜
            ),
            (
                RabbitMQConsumerConfig {
                    rabbitmq_url: "amqp://localhost:5672".to_string(),
                    exchange_name: "websocket_notifications".to_string(),
                    queue_name: "ws-server-2".to_string(),
                    routing_patterns: vec!["execution.*".to_string(), "orderbook.*".to_string()],
                    worker_id: "ws-worker-2".to_string(),
                    batch_size: 100,
                    processing_interval_ms: 100,
                },
                "ws-server-2".to_string(),
                1000, // ìµœëŒ€ ì—°ê²° ìˆ˜
            ),
            (
                RabbitMQConsumerConfig {
                    rabbitmq_url: "amqp://localhost:5672".to_string(),
                    exchange_name: "websocket_notifications".to_string(),
                    queue_name: "ws-server-3".to_string(),
                    routing_patterns: vec!["execution.*".to_string(), "orderbook.*".to_string()],
                    worker_id: "ws-worker-3".to_string(),
                    batch_size: 100,
                    processing_interval_ms: 100,
                },
                "ws-server-3".to_string(),
                1000, // ìµœëŒ€ ì—°ê²° ìˆ˜
            ),
        ];

        // ë¡œë“œë°¸ëŸ°ì„œ Consumer ì´ˆê¸°í™”
        match LoadBalancerConsumer::new(server_configs).await {
            Ok(load_balancer) => {
                println!("âœ… RabbitMQ ë¡œë“œë°¸ëŸ°ì„œ Consumer ì´ˆê¸°í™” ì™„ë£Œ");
                
                tokio::spawn(async move {
                    if let Err(e) = load_balancer.run().await {
                        println!("âŒ RabbitMQ ë¡œë“œë°¸ëŸ°ì„œ Consumer ì‹¤í–‰ ì˜¤ë¥˜: {}", e);
                    }
                });
            }
            Err(e) => {
                println!("âš ï¸ RabbitMQ ë¡œë“œë°¸ëŸ°ì„œ Consumer ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e);
            }
        }

        // Dead Letter Queue Consumer ì´ˆê¸°í™”
        let dlq_config = RabbitMQConsumerConfig {
            rabbitmq_url: "amqp://localhost:5672".to_string(),
            exchange_name: "websocket_notifications".to_string(),
            queue_name: "websocket_notifications.dlq".to_string(),
            routing_patterns: vec!["*".to_string()],
            worker_id: "dlq-worker".to_string(),
            batch_size: 50,
            processing_interval_ms: 5000, // 5ì´ˆë§ˆë‹¤ ì²˜ë¦¬
        };

        match DeadLetterQueueConsumer::new(dlq_config, 3).await {
            Ok(dlq_consumer) => {
                println!("âœ… RabbitMQ Dead Letter Queue Consumer ì´ˆê¸°í™” ì™„ë£Œ");
                
                tokio::spawn(async move {
                    if let Err(e) = dlq_consumer.run().await {
                        println!("âŒ RabbitMQ Dead Letter Queue Consumer ì‹¤í–‰ ì˜¤ë¥˜: {}", e);
                    }
                });
            }
            Err(e) => {
                println!("âš ï¸ RabbitMQ Dead Letter Queue Consumer ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e);
            }
        }
    }

    // ë§¤ì¹­ ì—”ì§„ ì‹¤í–‰ íƒœìŠ¤í¬ (ì‹œí€€ì„œì—ì„œ ì£¼ë¬¸ì„ ë°›ìŒ)
    let engine_clone = engine.clone();
    tokio::spawn(async move {
        let mut engine_guard = engine_clone.lock().await;
        engine_guard.run(sequencer_rx);
    });

    // MDPëŠ” ì´ì œ ì‹œí€€ì„œì—ì„œ ì§ì ‘ ì²˜ë¦¬ë¨

    // ì„œë²„ ìƒíƒœ ìƒì„±
    let state = ServerState {
        engine: engine.clone(),
        execution_tx: broadcast_tx,
        order_tx: order_tx,
        mdp: mdp.clone(),
        db_pool: db_pool.clone(),
    };

    // REST API ë¼ìš°í„° ìƒì„±
    let api_router = create_api_router()
        .layer(CorsLayer::permissive())
        .layer(TraceLayer::new_for_http())
        .with_state(state.clone());

    // REST API ì„œë²„ ì‹œì‘
    let listener = tokio::net::TcpListener::bind(format!("0.0.0.0:{}", config.rest_port))
        .await
        .expect("Failed to bind REST server");
    
    println!("ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!");
    println!("REST API: http://localhost:{}", config.rest_port);
    
    axum::serve(listener, api_router)
        .await
        .expect("REST server failed");

    Ok(())
}