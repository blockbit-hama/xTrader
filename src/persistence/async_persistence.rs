use std::sync::Arc;
use std::collections::VecDeque;
use std::time::Duration;
use tokio::sync::Mutex;
use tokio::time::interval;
use sqlx::SqlitePool;
use log::{debug, error, info, warn};
use serde::{Serialize, Deserialize};

use crate::matching_engine::model::ExecutionReport;
use crate::matching_engine::ultra_fast_engine::PersistenceTask;

/// ë¹„ë™ê¸° ì˜ì†í™” ë§¤ë‹ˆì €
/// 
/// í•µì‹¬ ê¸°ëŠ¥:
/// 1. ë°°ì¹˜ ì²˜ë¦¬ë¡œ DB ë¶€í•˜ ìµœì†Œí™”
/// 2. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬
/// 3. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
/// 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
pub struct AsyncPersistenceManager {
    /// DB ì—°ê²° í’€
    db_pool: SqlitePool,
    
    /// ì˜ì†í™” í
    persistence_queue: Arc<Mutex<VecDeque<PersistenceTask>>>,
    
    /// ë°°ì¹˜ í¬ê¸°
    batch_size: usize,
    
    /// ë°°ì¹˜ ê°„ê²© (ë°€ë¦¬ì´ˆ)
    batch_interval_ms: u64,
    
    /// ì„±ëŠ¥ ë©”íŠ¸ë¦­
    metrics: Arc<PersistenceMetrics>,
    
    /// ì¬ì‹œë„ í (ì‹¤íŒ¨í•œ ì‘ì—…ë“¤)
    retry_queue: Arc<Mutex<VecDeque<PersistenceTask>>>,
    
    /// ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    max_retries: usize,
}

/// ì˜ì†í™” ì„±ëŠ¥ ë©”íŠ¸ë¦­
#[derive(Debug, Default)]
pub struct PersistenceMetrics {
    pub total_batches: std::sync::atomic::AtomicU64,
    pub total_executions: std::sync::atomic::AtomicU64,
    pub successful_batches: std::sync::atomic::AtomicU64,
    pub failed_batches: std::sync::atomic::AtomicU64,
    pub total_latency_ms: std::sync::atomic::AtomicU64,
    pub start_time: std::time::Instant,
}

impl PersistenceMetrics {
    pub fn new() -> Self {
        Self {
            start_time: std::time::Instant::now(),
            ..Default::default()
        }
    }
    
    pub fn record_batch(&self, success: bool, latency_ms: u64, execution_count: usize) {
        self.total_batches.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        self.total_executions.fetch_add(execution_count as u64, std::sync::atomic::Ordering::Relaxed);
        self.total_latency_ms.fetch_add(latency_ms, std::sync::atomic::Ordering::Relaxed);
        
        if success {
            self.successful_batches.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        } else {
            self.failed_batches.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        }
    }
    
    pub fn get_tps(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        if elapsed > 0.0 {
            self.total_executions.load(std::sync::atomic::Ordering::Relaxed) as f64 / elapsed
        } else {
            0.0
        }
    }
    
    pub fn get_avg_latency_ms(&self) -> f64 {
        let total_batches = self.total_batches.load(std::sync::atomic::Ordering::Relaxed);
        if total_batches > 0 {
            self.total_latency_ms.load(std::sync::atomic::Ordering::Relaxed) as f64 / total_batches as f64
        } else {
            0.0
        }
    }
    
    pub fn get_success_rate(&self) -> f64 {
        let total_batches = self.total_batches.load(std::sync::atomic::Ordering::Relaxed);
        if total_batches > 0 {
            self.successful_batches.load(std::sync::atomic::Ordering::Relaxed) as f64 / total_batches as f64 * 100.0
        } else {
            0.0
        }
    }
}

impl AsyncPersistenceManager {
    /// ìƒˆ ë¹„ë™ê¸° ì˜ì†í™” ë§¤ë‹ˆì € ìƒì„±
    pub fn new(db_pool: SqlitePool) -> Self {
        Self {
            db_pool,
            persistence_queue: Arc::new(Mutex::new(VecDeque::new())),
            batch_size: 100,
            batch_interval_ms: 10,
            metrics: Arc::new(PersistenceMetrics::new()),
            retry_queue: Arc::new(Mutex::new(VecDeque::new())),
            max_retries: 3,
        }
    }
    
    /// ì„¤ì • ì—…ë°ì´íŠ¸
    pub fn with_config(mut self, batch_size: usize, batch_interval_ms: u64) -> Self {
        self.batch_size = batch_size;
        self.batch_interval_ms = batch_interval_ms;
        self
    }
    
    /// ì˜ì†í™” íì— ì‘ì—… ì¶”ê°€
    pub async fn queue_task(&self, task: PersistenceTask) {
        let mut queue = self.persistence_queue.lock().await;
        queue.push_back(task);
        debug!("ì˜ì†í™” ì‘ì—… íì— ì¶”ê°€ë¨ (í í¬ê¸°: {})", queue.len());
    }
    
    /// ë°°ì¹˜ ì»¤ë°‹ ë£¨í”„ ì‹¤í–‰
    pub async fn run_batch_commit_loop(&self) {
        info!("ğŸš€ ë¹„ë™ê¸° ì˜ì†í™” ë§¤ë‹ˆì € ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {}, ê°„ê²©: {}ms)", 
              self.batch_size, self.batch_interval_ms);
        
        let mut interval = interval(Duration::from_millis(self.batch_interval_ms));
        
        loop {
            interval.tick().await;
            
            // ë©”ì¸ íì—ì„œ ë°°ì¹˜ ì²˜ë¦¬
            let batch = self.drain_queue().await;
            if !batch.is_empty() {
                self.process_batch(batch).await;
            }
            
            // ì¬ì‹œë„ í ì²˜ë¦¬
            self.process_retry_queue().await;
            
            // ì£¼ê¸°ì ìœ¼ë¡œ ë©”íŠ¸ë¦­ ì¶œë ¥
            if self.metrics.total_batches.load(std::sync::atomic::Ordering::Relaxed) % 100 == 0 {
                self.print_metrics();
            }
        }
    }
    
    /// íì—ì„œ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
    async fn drain_queue(&self) -> Vec<PersistenceTask> {
        let mut queue = self.persistence_queue.lock().await;
        queue.drain(..self.batch_size.min(queue.len())).collect()
    }
    
    /// ë°°ì¹˜ ì²˜ë¦¬
    async fn process_batch(&self, batch: Vec<PersistenceTask>) {
        let start_time = std::time::Instant::now();
        let batch_size = batch.len();
        
        match self.commit_batch_to_db(&batch).await {
            Ok(_) => {
                let latency_ms = start_time.elapsed().as_millis() as u64;
                self.metrics.record_batch(true, latency_ms, batch_size);
                debug!("âœ… ë°°ì¹˜ ì»¤ë°‹ ì„±ê³µ: {}ê°œ ì‘ì—…, {}ms", batch_size, latency_ms);
            }
            Err(e) => {
                let latency_ms = start_time.elapsed().as_millis() as u64;
                self.metrics.record_batch(false, latency_ms, batch_size);
                error!("âŒ ë°°ì¹˜ ì»¤ë°‹ ì‹¤íŒ¨: {}ê°œ ì‘ì—…, {}ms, ì—ëŸ¬: {}", batch_size, latency_ms, e);
                
                // ì‹¤íŒ¨í•œ ì‘ì—…ë“¤ì„ ì¬ì‹œë„ íì— ì¶”ê°€
                self.add_to_retry_queue(batch).await;
            }
        }
    }
    
    /// DBì— ë°°ì¹˜ ì»¤ë°‹
    async fn commit_batch_to_db(&self, batch: &[PersistenceTask]) -> Result<(), sqlx::Error> {
        if batch.is_empty() {
            return Ok(());
        }
        
        let mut tx = self.db_pool.begin().await?;
        
        // ëª¨ë“  ì²´ê²° ë‚´ì—­ì„ í•˜ë‚˜ì˜ íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì²˜ë¦¬
        for task in batch {
            // ì²´ê²° ë‚´ì—­ ì €ì¥
            sqlx::query!(
                "INSERT INTO executions (exec_id, taker_order_id, maker_order_id, symbol, side, price, quantity, taker_fee, maker_fee, transaction_time)
                 VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                task.execution.execution_id,
                task.execution.order_id,
                task.execution.counterparty_id,
                task.execution.symbol,
                format!("{:?}", task.execution.side),
                task.execution.price as i64,
                task.execution.quantity as i64,
                0, // ìˆ˜ìˆ˜ë£ŒëŠ” ë‚˜ì¤‘ì— êµ¬í˜„
                0,
                task.execution.timestamp as i64
            )
            .execute(&mut tx)
            .await?;
            
            // ì£¼ë¬¸ ìƒíƒœ ì—…ë°ì´íŠ¸
            sqlx::query!(
                "UPDATE orders 
                 SET filled_quantity = filled_quantity + ?, 
                     status = CASE 
                         WHEN filled_quantity + ? >= quantity THEN 'Filled' 
                         ELSE 'PartiallyFilled' 
                     END,
                     updated_at = CURRENT_TIMESTAMP
                 WHERE order_id = ?",
                task.execution.quantity as i64,
                task.execution.quantity as i64,
                task.execution.order_id
            )
            .execute(&mut tx)
            .await?;
            
            // ì”ê³  ì—…ë°ì´íŠ¸
            sqlx::query!(
                "INSERT OR REPLACE INTO balances (client_id, asset, available, locked, updated_at)
                 VALUES (?, 'KRW', 
                         COALESCE((SELECT available FROM balances WHERE client_id = ? AND asset = 'KRW'), 0) + ?,
                         0, CURRENT_TIMESTAMP)",
                task.user_id,
                task.user_id,
                task.balance_delta
            )
            .execute(&mut tx)
            .await?;
            
            // ê°ì‚¬ ë¡œê·¸
            sqlx::query!(
                "INSERT INTO audit_log (timestamp, operation, details, user_id)
                 VALUES (?, ?, ?, ?)",
                task.timestamp as i64,
                "EXECUTION",
                format!("Execution {} completed", task.execution.execution_id),
                task.user_id
            )
            .execute(&mut tx)
            .await?;
        }
        
        tx.commit().await?;
        Ok(())
    }
    
    /// ì¬ì‹œë„ íì— ì¶”ê°€
    async fn add_to_retry_queue(&self, batch: Vec<PersistenceTask>) {
        let mut retry_queue = self.retry_queue.lock().await;
        for mut task in batch {
            task.timestamp = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos() as u64;
            retry_queue.push_back(task);
        }
        warn!("ì¬ì‹œë„ íì— {}ê°œ ì‘ì—… ì¶”ê°€ë¨", retry_queue.len());
    }
    
    /// ì¬ì‹œë„ í ì²˜ë¦¬
    async fn process_retry_queue(&self) {
        let mut retry_queue = self.retry_queue.lock().await;
        if retry_queue.is_empty() {
            return;
        }
        
        let batch: Vec<PersistenceTask> = retry_queue.drain(..self.batch_size.min(retry_queue.len())).collect();
        drop(retry_queue);
        
        if !batch.is_empty() {
            match self.commit_batch_to_db(&batch).await {
                Ok(_) => {
                    debug!("âœ… ì¬ì‹œë„ ë°°ì¹˜ ì„±ê³µ: {}ê°œ ì‘ì—…", batch.len());
                }
                Err(e) => {
                    error!("âŒ ì¬ì‹œë„ ë°°ì¹˜ ì‹¤íŒ¨: {}ê°œ ì‘ì—…, ì—ëŸ¬: {}", batch.len(), e);
                    // ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸ í›„ ë‹¤ì‹œ íì— ì¶”ê°€í•˜ê±°ë‚˜ í¬ê¸°
                    self.handle_retry_failure(batch).await;
                }
            }
        }
    }
    
    /// ì¬ì‹œë„ ì‹¤íŒ¨ ì²˜ë¦¬
    async fn handle_retry_failure(&self, batch: Vec<PersistenceTask>) {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ì¶”ì í•˜ê³  ìµœëŒ€ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ì•Œë¦¼
        warn!("ì¬ì‹œë„ ì‹¤íŒ¨í•œ ì‘ì—…ë“¤ì„ ë¡œê·¸ì— ê¸°ë¡: {}ê°œ", batch.len());
        for task in batch {
            error!("ì‹¤íŒ¨í•œ ì˜ì†í™” ì‘ì—…: execution_id={}, user_id={}", 
                   task.execution.execution_id, task.user_id);
        }
    }
    
    /// ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥
    pub fn print_metrics(&self) {
        let metrics = &self.metrics;
        info!("ğŸ“Š ì˜ì†í™” ì„±ëŠ¥ ë©”íŠ¸ë¦­:");
        info!("   ì´ ë°°ì¹˜ ìˆ˜: {}", metrics.total_batches.load(std::sync::atomic::Ordering::Relaxed));
        info!("   ì´ ì²´ê²° ìˆ˜: {}", metrics.total_executions.load(std::sync::atomic::Ordering::Relaxed));
        info!("   ì„±ê³µë¥ : {:.2}%", metrics.get_success_rate());
        info!("   ì²˜ë¦¬ëŸ‰: {:.2} TPS", metrics.get_tps());
        info!("   í‰ê·  ì§€ì—°: {:.2}ms", metrics.get_avg_latency_ms());
        
        let queue_size = {
            let queue = self.persistence_queue.try_lock().unwrap_or_default();
            queue.len()
        };
        let retry_size = {
            let retry_queue = self.retry_queue.try_lock().unwrap_or_default();
            retry_queue.len()
        };
        info!("   í í¬ê¸°: {} (ì¬ì‹œë„: {})", queue_size, retry_size);
    }
    
    /// í ìƒíƒœ ì¡°íšŒ
    pub async fn get_queue_status(&self) -> QueueStatus {
        let main_queue_size = self.persistence_queue.lock().await.len();
        let retry_queue_size = self.retry_queue.lock().await.len();
        
        QueueStatus {
            main_queue_size,
            retry_queue_size,
            total_pending: main_queue_size + retry_queue_size,
        }
    }
    
    /// ê°•ì œ ë°°ì¹˜ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)
    pub async fn force_process_batch(&self) -> Result<usize, sqlx::Error> {
        let batch = self.drain_queue().await;
        let batch_size = batch.len();
        
        if !batch.is_empty() {
            self.commit_batch_to_db(&batch).await?;
            debug!("ê°•ì œ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {}ê°œ ì‘ì—…", batch_size);
        }
        
        Ok(batch_size)
    }
}

/// í ìƒíƒœ ì •ë³´
#[derive(Debug, Clone)]
pub struct QueueStatus {
    pub main_queue_size: usize,
    pub retry_queue_size: usize,
    pub total_pending: usize,
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::matching_engine::model::{ExecutionReport, Side};
    use uuid::Uuid;
    
    fn create_test_execution() -> ExecutionReport {
        ExecutionReport {
            execution_id: Uuid::new_v4().to_string(),
            order_id: "order1".to_string(),
            symbol: "BTC-KRW".to_string(),
            side: Side::Buy,
            price: 10000,
            quantity: 100,
            remaining_quantity: 0,
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
            counterparty_id: "order2".to_string(),
            is_maker: false,
        }
    }
    
    fn create_test_task() -> PersistenceTask {
        PersistenceTask {
            execution: create_test_execution(),
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos() as u64,
            user_id: "user1".to_string(),
            balance_delta: 1000000,
        }
    }
    
    #[tokio::test]
    async fn test_persistence_manager_creation() {
        // ì‹¤ì œ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” í…ŒìŠ¤íŠ¸ìš© DBë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
        // let db_pool = create_test_db_pool().await;
        // let manager = AsyncPersistenceManager::new(db_pool);
        // assert_eq!(manager.batch_size, 100);
        // assert_eq!(manager.batch_interval_ms, 10);
    }
    
    #[tokio::test]
    async fn test_queue_task() {
        // let db_pool = create_test_db_pool().await;
        // let manager = AsyncPersistenceManager::new(db_pool);
        // let task = create_test_task();
        // 
        // manager.queue_task(task).await;
        // let status = manager.get_queue_status().await;
        // assert_eq!(status.main_queue_size, 1);
    }
    
    #[tokio::test]
    async fn test_metrics() {
        let metrics = PersistenceMetrics::new();
        
        metrics.record_batch(true, 10, 5);
        metrics.record_batch(false, 20, 3);
        
        assert_eq!(metrics.total_batches.load(std::sync::atomic::Ordering::Relaxed), 2);
        assert_eq!(metrics.total_executions.load(std::sync::atomic::Ordering::Relaxed), 8);
        assert_eq!(metrics.successful_batches.load(std::sync::atomic::Ordering::Relaxed), 1);
        assert_eq!(metrics.failed_batches.load(std::sync::atomic::Ordering::Relaxed), 1);
        assert_eq!(metrics.get_success_rate(), 50.0);
    }
}